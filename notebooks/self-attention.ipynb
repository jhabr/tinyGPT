{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e879513-52d3-4166-af8a-550f8da6309d",
   "metadata": {},
   "source": [
    "# Mathematical Trick for Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80bf77ab-5d35-4978-aefd-f2ebe402fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62bc744b-18bf-42f5-8cfb-004a31e5b200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105d63510>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e05237-a726-41cb-b299-8dab418501fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2 # batch, time, channels (i.e. # of tokens in vocabulary)\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c076d-a252-4904-abba-b421a8962828",
   "metadata": {},
   "source": [
    "## Bag Of Words (bow)\n",
    "\n",
    "== averaging\n",
    "\n",
    "### 1. For Loop\n",
    "Using for loop => not efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c212db-0ee3-4c8b-9ff8-c08ca9e42d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 1.4138, -0.3091],\n",
       "        [ 1.1687, -0.6176],\n",
       "        [ 0.8657, -0.8644],\n",
       "        [ 0.5422, -0.3617],\n",
       "        [ 0.3864, -0.5354],\n",
       "        [ 0.2272, -0.5388],\n",
       "        [ 0.1027, -0.3762]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow = torch.zeros((B, T, C))\n",
    "\n",
    "for batch in range(B):\n",
    "    for time in range(T):\n",
    "        x_prev = x[batch, :time+1]  # all previous tokens (up to time t) in this batch and sample\n",
    "        x_bow[batch, time] = torch.mean(x_prev, dim=0)\n",
    "\n",
    "x_bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a0fc3-6652-42e2-95c8-eb064b649291",
   "metadata": {},
   "source": [
    "### 2. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe742859-14a7-43c5-aa8f-5dc1de1abdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.ones(T, T)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89ad7f60-3e99-4a6c-a264-5115b1e89e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the future is not relevant for predictions, only look at the past\n",
    "weights = torch.tril(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7825bdd6-77ee-4e6c-b01d-cf78a76eee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights / weights.sum(axis=1, keepdim=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebbb73a1-46e3-481a-80d8-6f4f93d18fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 1.4138, -0.3091],\n",
       "        [ 1.1687, -0.6176],\n",
       "        [ 0.8657, -0.8644],\n",
       "        [ 0.5422, -0.3617],\n",
       "        [ 0.3864, -0.5354],\n",
       "        [ 0.2272, -0.5388],\n",
       "        [ 0.1027, -0.3762]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow2 = weights @ x\n",
    "x_bow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17383a55-7c10-43d7-a1fb-8b91d6ef8dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that both are similar\n",
    "torch.allclose(x_bow, x_bow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9cb69-4046-44fa-bf83-5b88cb51a310",
   "metadata": {},
   "source": [
    "### 3. Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57aba0f7-6e9b-43c1-a2a5-e15b78235f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones((T, T)))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b13446d-b55a-454c-b267-a897f7373a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float(\"-inf\"))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adf2b704-043e-48d9-ab85-f595a011ce03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.nn.functional.softmax(weights, dim=-1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "790a8948-1c63-4c44-8c63-c783a49259f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 1.4138, -0.3091],\n",
       "        [ 1.1687, -0.6176],\n",
       "        [ 0.8657, -0.8644],\n",
       "        [ 0.5422, -0.3617],\n",
       "        [ 0.3864, -0.5354],\n",
       "        [ 0.2272, -0.5388],\n",
       "        [ 0.1027, -0.3762]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow3 = weights @ x\n",
    "x_bow3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea77d1b1-f850-419d-b763-b69087e18f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(x_bow, x_bow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859c760-05c3-4a6c-84f5-dd3a64b71349",
   "metadata": {},
   "source": [
    "## Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2f3967c-0130-4c40-96ba-e7eab986798d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "B, T, C = 4, 8, 32 # batch, time, channels (i.e. # of tokens in vocabulary)\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape\n",
    "\n",
    "# single head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "# ---> here is what I have / what do I contain? / the evidence\n",
    "# get words that most closerly attent to current word\n",
    "k = key(x) # (B, T, head_size) => (4, 8, 16)\n",
    "# print(k.shape)\n",
    "\n",
    "# ---> here is what I'm interested in / what am I looking for / questions that I have /\n",
    "# in predicting next word, are we summarizing, translating or creating?\n",
    "q = query(x) # (B, T, head_size) => (4, 8, 16)\n",
    "# print(q.transpose(-2, -1).shape)  #  => (4, 16, 8)\n",
    "\n",
    "\n",
    "weights = q @ k.transpose(-2, -1)  # => (B, T, 16) @ (B, 16, T) => (B, T, T)  / dot product\n",
    "weights *= head_size ** -0.5  # scaling, otherwise the softmax will become too peaky => high initial values will get a high value after softmax\n",
    "\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "# weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float(\"-inf\"))  # only in decoder blocks; in encoder blocks, we allow each token to talk to each other\n",
    "weights = torch.nn.functional.softmax(weights, dim=-1)\n",
    "\n",
    "# out = weights @ x\n",
    "# ---> here is what I will communicate to you if you find me interesting / relevance of the evidence to solve the case\n",
    "# relevance of this pair to correct prediction\n",
    "v = value(x)\n",
    "out = weights @ v  # instead of the raw x values\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b4a1df8-e7d1-40f1-92e3-c51126ef0023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8990, 0.1010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3339, 0.4727, 0.1934, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4491, 0.0536, 0.3944, 0.1029, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0218, 0.5909, 0.1793, 0.1461, 0.0619, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4292, 0.1283, 0.0066, 0.0170, 0.0012, 0.4177, 0.0000, 0.0000],\n",
       "         [0.1479, 0.0274, 0.1908, 0.0884, 0.1558, 0.0718, 0.3179, 0.0000],\n",
       "         [0.4090, 0.0620, 0.0469, 0.0045, 0.0068, 0.1389, 0.2396, 0.0923]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2627, 0.7373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0712, 0.2229, 0.7059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4681, 0.1490, 0.3433, 0.0396, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0136, 0.1054, 0.0638, 0.4138, 0.4035, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0189, 0.2226, 0.5052, 0.0210, 0.0297, 0.2025, 0.0000, 0.0000],\n",
       "         [0.0094, 0.2618, 0.1434, 0.0603, 0.4879, 0.0301, 0.0071, 0.0000],\n",
       "         [0.7747, 0.1420, 0.0267, 0.0090, 0.0077, 0.0017, 0.0342, 0.0040]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4708, 0.5292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2214, 0.7043, 0.0742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2465, 0.3534, 0.3810, 0.0191, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1956, 0.0390, 0.5362, 0.0326, 0.1966, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0275, 0.0122, 0.0021, 0.9036, 0.0390, 0.0157, 0.0000, 0.0000],\n",
       "         [0.2761, 0.0216, 0.0797, 0.1034, 0.0513, 0.3079, 0.1599, 0.0000],\n",
       "         [0.0117, 0.0370, 0.0191, 0.6940, 0.0110, 0.0035, 0.0401, 0.1836]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5105, 0.4895, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1486, 0.1730, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0775, 0.2079, 0.3382, 0.3764, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3671, 0.1512, 0.2112, 0.1780, 0.0924, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0464, 0.5808, 0.0157, 0.1474, 0.0880, 0.1217, 0.0000, 0.0000],\n",
       "         [0.0426, 0.1844, 0.0591, 0.0654, 0.0223, 0.2672, 0.3591, 0.0000],\n",
       "         [0.0907, 0.0028, 0.3331, 0.2510, 0.0556, 0.0645, 0.1890, 0.0133]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d2159-030d-4869-90bb-b2ed81e94020",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- `Encoder`: no tril, allows all tokens to communicate.\n",
    "- `Decoder`: triangular masking, allows only to communicate with the past tokens.\n",
    "- `Self-Atttention`: `q`, `k`, `v` are produced from the same `x`.\n",
    "- `Cross-Attention`: `q` produced from `x` - `k`, `v` produced from other, external source (e.g. encoder module)\n",
    "- `Scaled Attention`: attention devided by `1/sqrt(head_size)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3c48f-3f86-41a7-8db4-717943572d5d",
   "metadata": {},
   "source": [
    "### Softmax Peakiness\n",
    "\n",
    "softmax will emphasize high values => sharpen towards highest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce328e81-d642-4837-af28-45b7b95c9be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2562, 0.1898, 0.1717, 0.3822])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.1, -0.2, -0.3, 0.5])\n",
    "s1 = torch.softmax(t, dim=0)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c41a26a5-8de9-428c-af29-af69971b5b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0091)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "25b26da7-e6d6-4f85-93fb-fcefafc92781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0390, 0.0035, 0.0016, 0.9559])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = torch.softmax(t * 8, dim=0)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1529924b-54c4-4b1c-8c7b-a70749112c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2218)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54792a6-eae7-47a9-b2e6-220d6a6f9fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation",
   "language": "python",
   "name": "foundation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
